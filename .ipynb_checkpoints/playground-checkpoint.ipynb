{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/devm2024/nmt_keras/raw/master/fra.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from string import digits\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines= pd.read_table('dataset/fra.txt', names=['eng', 'fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     eng            fr\n",
      "0    Go.          Va !\n",
      "1   Run!       Cours !\n",
      "2   Run!      Courez !\n",
      "3   Wow!    Ça alors !\n",
      "4  Fire!      Au feu !\n",
      "5  Help!    À l'aide !\n",
      "6  Jump.        Saute.\n",
      "7  Stop!   Ça suffit !\n",
      "8  Stop!        Stop !\n",
      "9  Stop!  Arrête-toi !\n"
     ]
    }
   ],
   "source": [
    "print(lines[:10])\n",
    "lines = lines[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.fr=lines.fr.apply(lambda x: x.lower())\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
    "lines.fr=lines.fr.apply(lambda x: re.sub(\"'\", '', x)).apply(lambda x: re.sub(\",\", ' COMMA', x))\n",
    "exclude = set(string.punctuation)\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.fr=lines.fr.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "remove_digits  = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "lines.fr=lines.fr.apply(lambda x: x.translate(remove_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.fr = lines.fr.apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>go</td>\n",
       "      <td>START_ va  _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>run</td>\n",
       "      <td>START_ cours  _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run</td>\n",
       "      <td>START_ courez  _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow</td>\n",
       "      <td>START_ ça alors  _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fire</td>\n",
       "      <td>START_ au feu  _END</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eng                     fr\n",
       "0    go        START_ va  _END\n",
       "1   run     START_ cours  _END\n",
       "2   run    START_ courez  _END\n",
       "3   wow  START_ ça alors  _END\n",
       "4  fire    START_ au feu  _END"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eng_words=set()\n",
    "for eng in lines.eng:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "    \n",
    "all_french_words=set()\n",
    "for fr in lines.fr:\n",
    "    for word in fr.split():\n",
    "        if word not in all_french_words:\n",
    "            all_french_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2146, 4567)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words), len(all_french_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum length of a French sentence - 13\n",
      "Maximum length of a English sentence - 5\n"
     ]
    }
   ],
   "source": [
    "lenght_list=[]\n",
    "for l in lines.fr:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "print(\"Maximum length of a French sentence -\", np.max(lenght_list))\n",
    "lenght_list=[]\n",
    "for l in lines.eng:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "print(\"Maximum length of a English sentence -\", np.max(lenght_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['COMMA', 'a', 'abandon', 'abhor', 'aboard', 'about', 'above', 'absent', 'absurd', 'accept', 'ache', 'ached', 'act', 'action', 'active', 'actor', 'acts', 'adaptable', 'addicted', 'adjust', 'admire', 'admit', 'adopted', 'adorable', 'adore', 'adores', 'adult', 'adults', 'advice', 'afford', 'afraid', 'after', 'afternoon', 'again', 'against', 'age', 'agent', 'agree', 'agreed', 'agrees', 'ahead', 'aim', 'aint', 'air', 'airs', 'alert', 'alibi', 'alive', 'all', 'allow']\n"
     ]
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_french_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_french_words)\n",
    "print(input_words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data  = np.zeros(\n",
    "    (len(lines.eng), 7),\n",
    "    dtype='int16')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(lines.fr), 17),\n",
    "    dtype='int16')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(lines.fr), 17, num_decoder_tokens),\n",
    "    dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(lines.eng, lines.fr)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = input_token_index[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[378  51   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LSTM Network</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
